{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ADeEPT9jMXU"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!unzip /content/drive/MyDrive/dacon/도배하자분류/open.zip -d /content/work_space\n",
        "%cd work_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGzLg7jPjUWx",
        "outputId": "d1ef7868-ca19-46e7-ca68-52cf6475f05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/work_space\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import timm\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':384,\n",
        "    'EPOCHS':30,\n",
        "    'LEARNING_RATE':1e-4,\n",
        "    'BATCH_SIZE':16,\n",
        "    'SEED':621\n",
        "}\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "CLS_MODEL_PATH = '/content/drive/MyDrive/dacon/도배하자분류/save_model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKrx7SOmjUUa"
      },
      "outputs": [],
      "source": [
        "remove_dict = {'가구수정': [0, 3, 7, 8, 10],\n",
        "                '걸래받이수정': [87, 144, 160, 188, 285],\n",
        "                '곰팡이' : [10, 33, 57, 63, 84, 100],\n",
        "                '꼬임' : [27, 30, 33, 39, 55, 63, 82, 93, 100, 103, 107, 124, 137, 140, 146, 148, 155, 166, 178, 179, 190, 192, 208],\n",
        "                '녹오염' : [0],\n",
        "                '들뜸' : [10, 53],\n",
        "                '면불량' : [86, 3, 22, 1, 4, 5, 7, 9, 10, 12, 18, 28, 30, 42, 44, 45, 46, 52, 53, 63, 66, 77, 78, 81, 84, 88, 90, 95, 96],\n",
        "                '몰딩수정': [16, 34],\n",
        "                '석고수정' : [20, 23, 25, 41, 42, 49, 53, 56],\n",
        "                '오염' : [ 5, 13, 14, 49, 59, 71, 75, 105, 123, 129, 136, 151, 153, 157, 159, 166, 187, 191, 220, 222, 225, 262, 266, 267, 270,\n",
        "                          279, 306, 328, 342, 344, 393, 434, 444, 449, 453, 493, 497, 533, 539, 577, 580, 586],\n",
        "                '오타공' : [3, 8, 34, 68, 123],\n",
        "                '울음' : [3, 4, 6, 10, 12, 14, 19],\n",
        "                '터짐' : [10, 17, 64, 83, 90, 92, 102, 114, 116, 129],\n",
        "                '피스': [2],\n",
        "                '훼손' : [8, 11, 13, 39, 47, 62, 105, 107, 117, 120, 155, 156, 157, 173, 195, 196, 202, 206, 213, 223, 225, 232, 241, 252, 264, 277,\n",
        "                         269, 291, 292, 297, 300, 302, 313, 342, 348, 361, 382, 386, 395, 402, 412, 416, 425, 437, 456, 486, 506, 517, 520, 522, 525, 541,\n",
        "                         556, 558, 578, 589, 609, 618, 635, 659, 661, 662, 663, 664, 666, 679, 685]\n",
        "               }\n",
        "\n",
        "\n",
        "all_img_list = glob.glob('./train/*/*')\n",
        "\n",
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = all_img_list\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[2])\n",
        "\n",
        "for k, v in remove_dict.items():\n",
        "    for i in v:\n",
        "        img_path = f'./train/{k}/{i}.png'\n",
        "        index = df[df['img_path'] == img_path].index\n",
        "        df.drop(index, axis=0, inplace=True)\n",
        "\n",
        "df.loc[df['img_path']=='./train/몰딩수정/1.png', 'label'] = '틈새과다'\n",
        "df.loc[df['img_path']=='./train/몰딩수정/26.png', 'label'] = '틈새과다'\n",
        "df.loc[df['img_path']=='./train/몰딩수정/32.png', 'label'] = '틈새과다'\n",
        "df.loc[df['img_path']=='./train/몰딩수정/50.png', 'label'] = '틈새과다'\n",
        "df.loc[df['img_path']=='./train/몰딩수정/91.png', 'label'] = '틈새과다'\n",
        "df.loc[df['img_path']=='./train/몰딩수정/124.png', 'label'] = '틈새과다'\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le_type0 = preprocessing.LabelEncoder()\n",
        "le_type1 = preprocessing.LabelEncoder()\n",
        "le_type2 = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit_transform(df['label'])\n",
        "\n",
        "label_transform = {'0' : ['곰팡이', '녹오염', '반점', '오염'],\n",
        "                   '1' : ['면불량', '석고수정', '오타공', '울음', '이음부불량', '터짐', '훼손', '피스'],\n",
        "                   '2' : ['가구수정', '걸레받이수정', '꼬임', '들뜸', '몰딩수정', '창틀,문틀수정', '틈새과다']}\n",
        "\n",
        "train, val, _, _ = train_test_split(df, df['label'], test_size=0.20, stratify=df['label'], random_state=CFG['SEED'])\n",
        "\n",
        "train_label3, val_label3 = train.copy(), val.copy()\n",
        "train_type0, val_type0 = train.copy(), val.copy()\n",
        "train_type1, val_type1 = train.copy(), val.copy()\n",
        "train_type2, val_type2 = train.copy(), val.copy()\n",
        "\n",
        "train_label3['label'] = train_label3['label'].apply(lambda label : [int(k) for k, v in label_transform.items() if label in v][0])\n",
        "val_label3['label'] = val_label3['label'].apply(lambda label : [int(k) for k, v in label_transform.items() if label in v][0])\n",
        "\n",
        "train_type0 = train[train['label'].isin(['곰팡이', '녹오염', '반점', '오염'])]\n",
        "val_type0 = val[val['label'].isin(['곰팡이', '녹오염', '반점', '오염'])]\n",
        "train_type0['label'] = le_type0.fit_transform(train_type0['label'])\n",
        "val_type0['label'] = le_type0.transform(val_type0['label'])\n",
        "\n",
        "train_type1 = train[train['label'].isin(['면불량', '석고수정', '오타공', '울음', '이음부불량', '터짐', '훼손', '피스'])]\n",
        "val_type1 = val[val['label'].isin(['면불량', '석고수정', '오타공', '울음', '이음부불량', '터짐', '훼손', '피스'])]\n",
        "train_type1['label'] = le_type1.fit_transform(train_type1['label'])\n",
        "val_type1['label'] = le_type1.transform(val_type1['label'])\n",
        "\n",
        "train_type2 = train[train['label'].isin(['가구수정', '걸레받이수정', '꼬임', '들뜸', '몰딩수정', '창틀,문틀수정', '틈새과다'])]\n",
        "val_type2 = val[val['label'].isin(['가구수정', '걸레받이수정', '꼬임', '들뜸', '몰딩수정', '창틀,문틀수정', '틈새과다'])]\n",
        "train_type2['label'] = le_type2.fit_transform(train_type2['label'])\n",
        "val_type2['label'] = le_type2.transform(val_type2['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipHZNy8BjUSG"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIj_x_Q-jUPv"
      },
      "outputs": [],
      "source": [
        "def make_weights(labels, nclasses):\n",
        "    labels = np.array(labels)\n",
        "    weight_arr = np.zeros_like(labels)\n",
        "\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    for cls in range(nclasses):\n",
        "        weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr)\n",
        "\n",
        "    return weight_arr\n",
        "\n",
        "train_sampler_weights = make_weights(train_type0['label'].values, len(np.unique(train_type0['label'])))\n",
        "train_sampler_weights = torch.DoubleTensor(train_sampler_weights)\n",
        "train_type0_train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sampler_weights, len(train_sampler_weights))\n",
        "\n",
        "train_sampler_weights = make_weights(train_type1['label'].values, len(np.unique(train_type1['label'])))\n",
        "train_sampler_weights = torch.DoubleTensor(train_sampler_weights)\n",
        "train_type1_train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sampler_weights, len(train_sampler_weights))\n",
        "\n",
        "train_sampler_weights = make_weights(train_type2['label'].values, len(np.unique(train_type2['label'])))\n",
        "train_sampler_weights = torch.DoubleTensor(train_sampler_weights)\n",
        "train_type2_train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sampler_weights, len(train_sampler_weights))\n",
        "# train_class_weights = torch.FloatTensor(compute_class_weight(class_weight = \"balanced\" , classes=np.unique(train_type0['label']), y=train_type0['label'])).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bEhGEDWjUKz"
      },
      "outputs": [],
      "source": [
        "train_transform = A.Compose([\n",
        "                    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE'], p=1.0),\n",
        "                    A.HorizontalFlip(always_apply=False, p=0.6),\n",
        "                    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.05, 0.05), shift_limit_y=(-0.05, 0.05),\n",
        "                                       scale_limit=(-0.250, 0.100), rotate_limit=(-15, 15), interpolation=0, border_mode=0, value=(0, 0, 0)),\n",
        "                    A.RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.05, 0.15), contrast_limit=(-0.05, 0.15), brightness_by_max=True),\n",
        "                    A.RGBShift(always_apply=False, p=0.4, r_shift_limit=(-10, 10), g_shift_limit=(-10, 10), b_shift_limit=(-10, 10)),\n",
        "                    A.ColorJitter(always_apply=False, p=0.4, brightness=(1.0, 1.0), contrast=(1.0, 1.0), saturation=(0.8, 1.2), hue=(-0.05, 0.05)),\n",
        "                    A.GaussNoise(always_apply=False, p=0.4, var_limit=(15.00, 30.00), per_channel=True, mean=0.0),\n",
        "                    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                    ToTensorV2()\n",
        "                    ])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE'], p=1.0),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "\n",
        "train_label3_dataset = CustomDataset(train_label3['img_path'].values, train_label3['label'].values, train_transform)\n",
        "train_label3_loader = DataLoader(train_label3_dataset, batch_size = CFG['BATCH_SIZE'],  shuffle=True, num_workers=4)\n",
        "val_label3_dataset = CustomDataset(val_label3['img_path'].values, val_label3['label'].values, test_transform)\n",
        "val_label3_loader = DataLoader(val_label3_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "\n",
        "train_type0_dataset = CustomDataset(train_type0['img_path'].values, train_type0['label'].values, train_transform)\n",
        "train_type0_loader = DataLoader(train_type0_dataset, batch_size = CFG['BATCH_SIZE'], sampler=train_type0_train_sampler, shuffle=False, num_workers=4)\n",
        "val_type0_dataset = CustomDataset(val_type0['img_path'].values, val_type0['label'].values, test_transform)\n",
        "val_type0_loader = DataLoader(val_type0_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "\n",
        "train_type1_dataset = CustomDataset(train_type1['img_path'].values, train_type1['label'].values, train_transform)\n",
        "train_type1_loader = DataLoader(train_type1_dataset, batch_size = CFG['BATCH_SIZE'], sampler=train_type1_train_sampler, shuffle=False, num_workers=4)\n",
        "origin_train_dataset = CustomDataset(train_type1['img_path'].values, train_type1['label'].values, test_transform)\n",
        "origin_train_loader = DataLoader(origin_train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "val_type1_dataset = CustomDataset(val_type1['img_path'].values, val_type1['label'].values, test_transform)\n",
        "val_type1_loader = DataLoader(val_type1_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "\n",
        "train_type2_dataset = CustomDataset(train_type2['img_path'].values, train_type2['label'].values, train_transform)\n",
        "train_type2_loader = DataLoader(train_type2_dataset, batch_size = CFG['BATCH_SIZE'], sampler=train_type2_train_sampler, shuffle=False, num_workers=4)\n",
        "val_type2_dataset = CustomDataset(val_type2['img_path'].values, val_type2['label'].values, test_transform)\n",
        "val_type2_loader = DataLoader(val_type2_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRaQR2smjUIc"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        alpha: float = 1,\n",
        "        gamma: float = 2.0,\n",
        "        weight=None,\n",
        "        label_smoothing: float = 0.0,\n",
        "        reduction: str = \"mean\",\n",
        "    ) -> None:\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inp: torch.Tensor, targ: torch.Tensor):\n",
        "        ce_loss = F.cross_entropy(\n",
        "            inp,\n",
        "            targ,\n",
        "            weight=self.weight,\n",
        "            label_smoothing=self.label_smoothing,\n",
        "            reduction=\"none\",\n",
        "        )\n",
        "        p_t = torch.exp(-ce_loss)\n",
        "        loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            loss = loss.mean()\n",
        "        elif self.reduction == \"sum\":\n",
        "            loss = loss.sum()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sblTn8jrBXsJ"
      },
      "outputs": [],
      "source": [
        "class ArcFaceClassifier(nn.Module):\n",
        "    r\"\"\"Implement of large margin arc distance: :\n",
        "        Args:\n",
        "            in_features: size of each input sample\n",
        "            out_features: size of each output sample\n",
        "            s: norm of input feature\n",
        "            m: margin\n",
        "            cos(theta + m)\n",
        "        \"\"\"\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
        "        super(ArcFaceClassifier, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "\n",
        "        if label is not None:\n",
        "            sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
        "            phi = cosine * self.cos_m - sine * self.sin_m\n",
        "            if self.easy_margin:\n",
        "                phi = torch.where(cosine > 0, phi, cosine)\n",
        "            else:\n",
        "                phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "            # --------------------------- convert label to one-hot ---------------------------\n",
        "            # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
        "            one_hot = torch.zeros(cosine.size(), device=label.device)\n",
        "            one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "            # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
        "            output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
        "            output *= self.s\n",
        "            return output\n",
        "        else:\n",
        "            return cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1puNbEpjUDh"
      },
      "outputs": [],
      "source": [
        "class BaseModel_label3(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(BaseModel_label3, self).__init__()\n",
        "        self.backbone =  timm.create_model('tf_efficientnetv2_s_in21ft1k', pretrained=True)\n",
        "        in_features  = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "                                              nn.Dropout(0.4),\n",
        "                                              nn.Linear(in_features, num_classes)\n",
        "                                              )\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseModel_type0(nn.Module):\n",
        "    def __init__(self, num_classes=len(le_type0.classes_)):\n",
        "        super(BaseModel_type0, self).__init__()\n",
        "        self.backbone =  timm.create_model('tf_efficientnetv2_m_in21ft1k', pretrained=True)\n",
        "        in_features  = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "                                              nn.Dropout(0.4),\n",
        "                                              nn.Linear(in_features, num_classes)\n",
        "                                              )\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseModel_type1(nn.Module):\n",
        "  def __init__(self, num_classes=len(le_type1.classes_)):\n",
        "      super(BaseModel_type1, self).__init__()\n",
        "      self.backbone = timm.create_model('tf_efficientnetv2_m_in21ft1k', pretrained=True)\n",
        "      in_features  = self.backbone.classifier.in_features\n",
        "      self.backbone.classifier = nn.Identity()\n",
        "      self.embeddings = nn.Linear(in_features, 256)\n",
        "      self.classifier = ArcFaceClassifier(256, num_classes)\n",
        "\n",
        "  def forward(self, x, labels=None, return_embeddings=True):\n",
        "      x = self.backbone(x)\n",
        "      embeddings = self.embeddings(x)\n",
        "      if not return_embeddings:\n",
        "          logits = self.classifier(embeddings, labels)\n",
        "          return logits\n",
        "      else:\n",
        "          return F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "\n",
        "class BaseModel_type2(nn.Module):\n",
        "    def __init__(self, num_classes=len(le_type2.classes_)):\n",
        "        super(BaseModel_type2, self).__init__()\n",
        "        self.backbone =  timm.create_model('tf_efficientnetv2_m_in21ft1k', pretrained=True)\n",
        "        in_features  = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "                                              nn.Dropout(0.4),\n",
        "                                              nn.Linear(in_features, num_classes)\n",
        "                                              )\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYt4gFcdjUBb"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, type_='score', verbose=False, delta=0, trace_func=print):\n",
        "        self.patience = patience\n",
        "        self.type_ = type_\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.stop = False\n",
        "        self.val_acc_max = np.Inf\n",
        "        self.delta = delta\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "\n",
        "        if self.type_ == 'score':\n",
        "            score = val_acc\n",
        "        elif self.type_ == 'loss':\n",
        "            score = -val_acc\n",
        "        update_info = bool()\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            update_info = True\n",
        "            return update_info\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            update_info = False\n",
        "            if self.counter >= self.patience:\n",
        "                self.stop = True\n",
        "            return update_info\n",
        "\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "            update_info = True\n",
        "            return update_info\n",
        "\n",
        "def get_lr_at_epoch(cur_epoch, warmup_epoch=5, max_epcoh=30):\n",
        "    lr = lr_func_cosine(cur_epoch, offset=warmup_epoch, max_epcoh=max_epcoh)\n",
        "    # Perform warm up.\n",
        "    if cur_epoch < warmup_epoch:\n",
        "        lr_start = 1e-6\n",
        "        lr_end = lr_func_cosine(warmup_epoch, offset=warmup_epoch, max_epcoh=max_epcoh)\n",
        "        alpha = (lr_end - lr_start) / warmup_epoch\n",
        "        lr = cur_epoch * alpha + lr_start\n",
        "    return lr\n",
        "\n",
        "def lr_func_cosine(cur_epoch, base_lr=CFG['LEARNING_RATE'], offset=5, max_epcoh=30):\n",
        "    return (1e-6 + (base_lr - 1e-6) * (math.cos(\n",
        "                math.pi * (cur_epoch - offset) / (max_epcoh - offset)) + 1.0 ) * 0.5)\n",
        "\n",
        "def set_lr(optimizer, new_lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = new_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA0q6qgpjT_E"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, origin_train_loader, val_loader, scheduler, early_stopping, model_type, device):\n",
        "    model.to(device)\n",
        "    # ce_criterion = nn.CrossEntropyLoss().to(device)\n",
        "    ce_criterion = FocalLoss(label_smoothing=0.1).to(device)\n",
        "\n",
        "    best_model = None\n",
        "    warmup_epoch = 10\n",
        "\n",
        "    for epoch in range(CFG['EPOCHS']):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "\n",
        "        for iteration, (imgs, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "            epoch_exact = epoch + float(iteration) / len(train_loader)\n",
        "            new_lr = get_lr_at_epoch(epoch_exact, warmup_epoch, max_epcoh=CFG['EPOCHS'])\n",
        "            set_lr(optimizer, new_lr)\n",
        "\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(model, BaseModel_type1):\n",
        "                output = model(imgs, labels, return_embeddings=False)\n",
        "            else:\n",
        "                output = model(imgs)\n",
        "\n",
        "            loss = ce_criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _train_loss = np.mean(train_loss)\n",
        "\n",
        "        if isinstance(model, BaseModel_type1):\n",
        "            _val_loss, _val_acc, _val_score, _val_cos_score = arc_validation(model, origin_train_loader, val_loader, device)\n",
        "            print(f'Epoch [{epoch+1}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}] COS Val Weighted F1 Score : [{_val_cos_score:.5f}]')\n",
        "        else:\n",
        "            _val_loss, _val_acc, _val_score = validation(model, ce_criterion, val_loader, device)\n",
        "            print(f'Epoch [{epoch+1}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val acc : [{_val_acc:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
        "\n",
        "        if early_stopping(_val_score):\n",
        "            best_model = model\n",
        "            best_epoch = epoch+1\n",
        "\n",
        "        if early_stopping.stop:\n",
        "              break\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_score)\n",
        "\n",
        "    torch.save(best_model, f'{CLS_MODEL_PATH}{model_type}_epoch{best_epoch}.pt')\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nqMsoaAjT8w"
      },
      "outputs": [],
      "source": [
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    preds, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            true_labels += labels.detach().cpu().numpy().tolist()\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "        _val_acc = np.mean(np.array(preds)==np.array(true_labels))\n",
        "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
        "\n",
        "    return _val_loss, _val_acc, _val_score\n",
        "\n",
        "def arc_validation(model, origin_train_loader, val_loader, device):\n",
        "    num_class = 8\n",
        "    centroids = torch.zeros((num_class, 256), device=device)\n",
        "    counts = torch.zeros(num_class, device=device)\n",
        "\n",
        "    model.eval()\n",
        "    embedding_list, labels_list = [], []\n",
        "    val_loss, preds, cos_pred, true_labels = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(origin_train_loader)):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            embeddings = model(imgs, None, return_embeddings=True)\n",
        "\n",
        "            for emb, label in zip(embeddings, labels):\n",
        "                centroids[label] += emb\n",
        "                counts[label] += 1\n",
        "\n",
        "            embedding_list.append(embeddings.detach().cpu().numpy())\n",
        "            labels_list.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        for i in range(num_class):\n",
        "            if counts[i] > 0:\n",
        "                centroids[i] /= counts[i]\n",
        "\n",
        "        centroids = centroids.detach().cpu().numpy()\n",
        "        embedding_list = np.vstack(embedding_list)\n",
        "        labels_list = np.concatenate(labels_list)\n",
        "\n",
        "        knn = KNeighborsClassifier(metric='cosine')\n",
        "        knn.fit(embedding_list, labels_list)\n",
        "\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            embeddings = model(imgs)\n",
        "\n",
        "            embeddings = embeddings.detach().cpu().numpy()\n",
        "\n",
        "            cos_dis = cosine_similarity(embeddings, centroids)\n",
        "            cos_pred += cos_dis.argmax(1).tolist()\n",
        "\n",
        "            preds += knn.predict(embeddings).tolist()\n",
        "            true_labels += labels.detach().cpu().numpy().tolist()\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "        _val_acc = np.mean(np.array(preds)==np.array(true_labels))\n",
        "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
        "        _val_cos_score = f1_score(true_labels, cos_pred, average='weighted')\n",
        "\n",
        "    return _val_loss, _val_acc, _val_score, _val_cos_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grrHB_l50GEt"
      },
      "source": [
        "**TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugrK1YflF-48"
      },
      "outputs": [],
      "source": [
        "model_type = 'label3'\n",
        "model = BaseModel_label3()\n",
        "\n",
        "model.eval()\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=0.05)\n",
        "early_stopping = EarlyStopping(patience=10, type_='score', verbose=False)\n",
        "scheduler = None\n",
        "infer_model = train(model, optimizer, train_label3_loader, None, val_label3_loader, scheduler, early_stopping, model_type, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVqlahZAjT6a"
      },
      "outputs": [],
      "source": [
        "model_type = 'type0'\n",
        "model = BaseModel_type0()\n",
        "\n",
        "model.eval()\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=0.05)\n",
        "early_stopping = EarlyStopping(patience=10, type_='score', verbose=False)\n",
        "scheduler = None\n",
        "infer_model = train(model, optimizer, train_type0_loader, None, val_type0_loader, scheduler, early_stopping, model_type, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScoqLdqlDfgX"
      },
      "outputs": [],
      "source": [
        "model_type = 'type1'\n",
        "model = BaseModel_type1()\n",
        "\n",
        "model.eval()\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=0.05)\n",
        "early_stopping = EarlyStopping(patience=10, type_='score', verbose=False)\n",
        "scheduler = None\n",
        "infer_model = train(model, optimizer, train_type1_loader, origin_train_loader, val_type1_loader, scheduler, early_stopping, model_type, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-cFmRwSZXUZ"
      },
      "outputs": [],
      "source": [
        "model_type = 'type2'\n",
        "model = BaseModel_type2()\n",
        "\n",
        "model.eval()\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=0.05)\n",
        "early_stopping = EarlyStopping(patience=10, type_='score', verbose=False)\n",
        "scheduler = None\n",
        "infer_model = train(model, optimizer, train_type2_loader, None, val_type2_loader, scheduler, early_stopping, model_type, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYF5sEHFE0DQ"
      },
      "outputs": [],
      "source": [
        "def get_knn(model, origin_train_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    embedding_list, labels_list = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(origin_train_loader)):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            embeddings = model(imgs, None, return_embeddings=True)\n",
        "\n",
        "            embedding_list.append(embeddings.detach().cpu().numpy())\n",
        "            labels_list.append(labels.detach().cpu().numpy())\n",
        "            \n",
        "        embedding_list = np.vstack(embedding_list)\n",
        "        labels_list = np.concatenate(labels_list)\n",
        "\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "    param_grid = {\n",
        "        'n_neighbors': range(4, 10),\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
        "        'metric' : ['minkowski', 'cosine', 'euclidean', 'l1', 'l2']\n",
        "    }\n",
        "    grid_search = GridSearchCV(\n",
        "        knn,\n",
        "        param_grid=param_grid,\n",
        "        scoring=scorer,\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(embedding_list, labels_list)\n",
        "\n",
        "    print(f\"Best parameter: {grid_search.best_params_}\")\n",
        "    print(f\"Best score: {grid_search.best_score_}\")\n",
        "\n",
        "    knn = KNeighborsClassifier(**grid_search.best_params_)\n",
        "    knn.fit(embedding_list, labels_list)\n",
        "\n",
        "    return knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4yA8mqCgtIK"
      },
      "outputs": [],
      "source": [
        "def inference(label3_model, model_dict, knn, test_df, device):\n",
        "    label3_model.eval()\n",
        "\n",
        "    test_transform = A.Compose([\n",
        "                            A.Resize(384, 384, p=1.0),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "    test_dataset = CustomDataset(test_df['img_path'].values, None, test_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "\n",
        "    label3_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(iter(test_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "\n",
        "            label3_pred = label3_model(imgs)\n",
        "            label3_preds += label3_pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    test_df['label3'] = label3_preds\n",
        "\n",
        "    type0 = test_df[test_df['label3'] == 0]\n",
        "    type1 = test_df[test_df['label3'] == 1]\n",
        "    type2 = test_df[test_df['label3'] == 2]\n",
        "    type_list = [type0, type1, type2]\n",
        "\n",
        "    for i, model_type in enumerate(model_dict):\n",
        "        preds = []\n",
        "        model = model_dict[model_type]['model']\n",
        "        img_size = model_dict[model_type]['img_size']\n",
        "        le_type = model_dict[model_type]['le_type']\n",
        "        model.eval()\n",
        "\n",
        "        test_transform = A.Compose([\n",
        "                            A.Resize(img_size, img_size, p=1.0),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "        test_dataset = CustomDataset(type_list[i]['img_path'].values, None, test_transform, mode='test')\n",
        "        test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for imgs in tqdm(iter(test_loader)):\n",
        "                imgs = imgs.float().to(device)\n",
        "                if isinstance(model, BaseModel_type1):\n",
        "                    pred = model(imgs)\n",
        "                    preds += knn.predict(pred.detach().cpu().numpy()).tolist()\n",
        "                else:\n",
        "                    pred = model(imgs)\n",
        "                    preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "\n",
        "\n",
        "        preds = le_type.inverse_transform(preds)\n",
        "        type_list[i]['label'] = preds\n",
        "\n",
        "        for data in type_list[i].iterrows():\n",
        "            test_df.loc[test_df['id']==data[1]['id'], 'label3'] = data[1]['label']\n",
        "\n",
        "    return test_df, type_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQ-Rk5p0M6f"
      },
      "source": [
        "**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fujp3kcCL3uw"
      },
      "outputs": [],
      "source": [
        "label3_model = BaseModel_label3()\n",
        "label3_model = torch.load(f'{CLS_MODEL_PATH}label3_epoch28.pt', map_location=device)\n",
        "type0_model = BaseModel_type0()\n",
        "type0_model = torch.load(f'{CLS_MODEL_PATH}tpye0_epoch10.pt', map_location=device)\n",
        "type1_model = BaseModel_type1()\n",
        "type1_model = torch.load(f'{CLS_MODEL_PATH}tpye1_epoch30.pt', map_location=device)\n",
        "type2_model = BaseModel_type2()\n",
        "type2_model = torch.load(f'{CLS_MODEL_PATH}tpye2_epoch15.pt', map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0McLi1etE5Fb"
      },
      "outputs": [],
      "source": [
        "knn = get_knn(type1_model, origin_train_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ark3rOfBE67R"
      },
      "outputs": [],
      "source": [
        "model_dict = {'type0_model': {'model': type0_model,\n",
        "                              'img_size': 440,\n",
        "                              'le_type' : le_type0},\n",
        "\n",
        "              'type1_model':{'model': type1_model,\n",
        "                              'img_size': 440,\n",
        "                              'le_type' : le_type1},\n",
        "\n",
        "              'type2_model':{'model': type2_model,\n",
        "                              'img_size': 384,\n",
        "                              'le_type' : le_type2}\n",
        "}\n",
        "\n",
        "test_df = pd.read_csv('./test.csv')\n",
        "pred_df, _ = inference(label3_model, model_dict, knn, test_df, device)\n",
        "\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['label'] = pred_df['label3']\n",
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
